# 一种多巴胺驱动的欢乐学习算法

## 游戏设置
总共N道题，对应N个确切的学习小主题，(Problem_i。∈[1,N]),N Problem Topics,Problem_i。
N道题依序构成学习路径；N道题之间按语义相近度，互为邻域问题。

每个主题题目具有：
    邻域主题:
        这些领域主题是和当前主题最相关，但是不同于当前主题的其他主题。(ProblemNeibor_i,j)，(ProblemNeibor_i,j)，(j∈[1,N]，j!=i).
        邻域主题数量为3个
    知识点：
        - ​每个主题包含4组知识点(j∈[1,4])。
        - 可以拆包成不同权重的四份知识点。ProblemAnswer_i,j ProblemAnswerWeightt_i,j 
        - 知识点的权重是整数 1到10之间的值。
    每个知识点有一个权重值(ProblemAnswerWeight_i,j)，表示该知识点在该主题中的重要性。

## 游戏规则：
    1.先选下一个还没有完成的主题。
    2.选中该主题和3个邻域主题，形成一个主题包。
    3.把主题包的所有知识点合并，随机大三，并且重新拆分成4组答案。
    4.对主题进行提问，比如那个是词语认真
    5.用户可以点击两个答案组。
    6.每点击一个答案组，权重得分就加上和该问题相关的权重分。同时播放关于该答案的点评。该答案点评是用第一人称的方式。
    7.如果回答总得分高于权重逆序，序数为1、3的权重的总和。则给与额外的金南瓜🎃奖
​    8.重复1-7，直到所有主题都完成。
    9.每个主题完成后，在Hall-Of-Fame中显式排名信息。
       总积分榜单包括总权重得分和金南瓜🎃奖的数量。排行榜单有季度榜单和年度榜单。
## 游戏激励:
    1.可变奖励（Variable Rewards）:
        引入“暴击”概念。比如，用户首次点击的答案组中，如果恰好包含了当前问题最核心的那个知识点（权重最高），除了基础得分外，可以触发一个“完美命中！”的动画，随机并给予1.5倍-3倍的权重积分。
        引入“超级暴击”概念。比如，用户连续两次以上首次点击的答案组中，都恰好包含了当前问题最核心的那个知识点（权重最高），除了基础得分外，可以触发一个“超级暴击！”的动画，随机并给予2倍-4倍的权重积分。
    2. “金南瓜🎃”的稀缺性和随机性: 金南瓜的获取条件可以变得更“神秘”。例如，“在本次回答中，你选择的两个答案组恰好完美避开了所有来自邻域主题的干扰项” 则0.25几率出现；或者“你连续三次回答都触发了‘完美命中’”，且回答速度低于或等于平均速度，则0.8几率“嘭”地跳出一个巨大的金南瓜。这种“意外之喜”会带来巨大的多巴胺飙升，让用户对下一次的“大奖”充满期待。
    3. 增加“差一点就成功”（Near Miss）的反馈: 如果用户的总得分非常接近金南瓜的阈值（两次），但没达到，可以给一个特殊的反馈，比如：“哇！就差一点点金南瓜就是你的了！” 这会利用“损失厌恶”（Loss Aversion）和“蔡格尼克记忆效应”（Zeigarnik Effect，对未完成任务的记忆更深刻），极大地激发用户再来一次的动力。
       
## 一些关键思路和细节：
​   - 设计思路 多巴胺是一种大脑学习的专注性算法。它使得用户在情形高度不确定，正反局面的可能性都接近50%的时候，使得多巴胺大量分泌，从而使得学习者保持专注
   - 设计思路 几乎任何点击都会有欢乐的奖励提示。
   - 设计思路 这种反思有第一人称心理活动的视角点评呈现。学习者的心理活动可以帮助学习者更好地理解和记忆。而第一人称视角强化了心理活动的感觉。
   - 细节 第一人称视角点评加深了对细节的反复反思，
   - 领域主题和当前知识点的作为学习材料的反复出现，为高速认知上的高速处理提供认知预备。从而让整个学习过程有流畅和高效的爽感。
   - 动态难度调节（Dynamic Difficulty Adjustment）:
        新手阶段: 对于一个全新的主题，可以先从“1主+1邻”开始，即8个知识点重组成4组。让用户先建立初步的认知。
        熟练阶段: 如果用户答对，系统自动增加难度，变为“1主+2邻”，乃至最终的“1主+3邻”，反之减少一个领域问题，直到最少“1主+1邻”。

   - 问题路径:答题路径与邻域问题的编排：引入“间隔重复”与“遗忘曲线”，
现在请从大脑学习的第一性原理，如多巴胺工作机制和其它认知心理学原理，改善这个学习流程。