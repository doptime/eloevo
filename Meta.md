这部分的讨论旨在实现世界模拟器
进一步来说，很久以前我做梦的时候梦见的模拟世界中海量的工具能理解世界的意图，移动在模拟世界中，进行对模拟这个世界的打磨。以后我打算把它叫做工具个体。
工具个体建构世界的算法实现看起来极度极度简洁。因为一切都是对等的工具。哪怕是中央调度的工具，也可以是对等的。与此同时。只要有合适的规则，通过一种梯度优化的方式，工具很快将变得又多又精确又高效。
而我还看不出任何别的世界建构方式，能比这种方式更优。


工具个体的全局逻辑完备性如何成为可能
1. 认知的完备性如何成为可能。诸如逻辑操作，系统分析这样的活动可以在系统内部完成。但 模拟世界的性能是外部性的，其性能推理需要涉及系统的外部。如果性能检测器是主动式的，系统评估期需要收集问题域，以便界定问题的规模。如果性能探测器是被动式的，那么需要接口来容纳问题域的定义。此后他们都需要形成性能推理模型。 总之，需要存在系统性能评估者来达成完备性建模。
2. 工具个体的逻辑自洽性如何成为可能。
2.1 全局逻辑自洽的大前提。
  不同的AI有各自的认知域。当A生成对B而言是不完备的认知的时候。由于不完备性的不可知性，B 无法正确加工这一部分的不完备性，如果试图对这部分的加工做输出，那么B的逻辑自洽性就会被破坏。
进一步来说，如果事实涉及的先验对A B而言都不完备，那么无论如何无法构建面向目标性能的逻辑自洽结构。
所以，对于单模型不完备的问题来说，更强的模型的引入是不可避免的。这意味着一个更强模型的引入或者是更多模型的引入开始变得不可避免。
2.2   先验的自洽之先验如何在模型之间平滑
    2.2.1 模块之内的先验自洽
  1)由于先验依赖于模型，所以一个基于模型的工具性实现，要跨模型使用，a)若单独每一个模型先验都足够，那么多模型不是必要的b)如果需要多模型才能联合实现，那么这种联合由于是跨维度的，这种联合是实际不可能的。c)所以模型的工具化要求单模型。 
    ChatGPT 指出。如果存在第三个具有高可信先验，那么可以通过它施加一个协议或规范，使得两模型可以实现基于规范的b)的联合。但是我宁愿放弃这个成本极高的操作。因为它又需要用成本极度高昂的东西，来争论细枝末节。结构的合理性应该交给进化，交给性能测度论。它应该是行为主义的东西。裁决太难，不是端对端，对最终性能有损。
    2.2.2模块之间的自洽
    模块之间就没啥好说了，模块之间可以看做隔离的。但这里需要一个模块结构迭代者。



在Ponder 这里。我打算开发大量的各种不同的工具，用来协同解决问题。我应该如何使用单个模型，自动地开发各种工具。这些工具的prompt 应该是什么？然后不同的工具之间如何进行互相调用，切换？我应该如何分析才能继续推进这个项目？